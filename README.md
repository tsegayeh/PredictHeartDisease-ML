# ML_models_R
## Predicting heart disease: Comparison of six ML algorithms<br />
This work is an extension of my final project that I submitted to UCLA Data Science program in Fall 2020. The dataset heart.dat was obtained from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29). I have implemented the following six algorithms with the heart data to predict the presence or absence of heart disease in patients:<br /> 
* [eXtreme Gradient Boost](https://github.com/tsegayeh/ml_models_in_R/blob/main/Part_2.1_Models_XGBoost.R),<br /> 
* [Decision Tree](https://github.com/tsegayeh/ml_models_in_R/blob/main/Part_2.2_DecisionTree.R), <br />
* [Random Forest](https://github.com/tsegayeh/ml_models_in_R/blob/main/Part_2.3_RandomF.R), <br />
* [GLM](https://github.com/tsegayeh/ml_models_in_R/blob/main/Part_2.4_GLM.R), <br />
* [Naive Bayes](https://github.com/tsegayeh/ml_models_in_R/blob/main/Part_2.4_NaiveB.R), and <br />
* [SVM](https://github.com/tsegayeh/ml_models_in_R/blob/main/Part_2.6_SVM.R) <br />

I considered [eXtreme Gradient Boost](https://github.com/tsegayeh/ml_models_in_R/blob/main/Part_2.1_Models_XGBoost.R) model as superior in prediction, with an accuracy of 97% and covering 91% of the Area Under the Curve (AUC), followed by the [Decision Tree](https://github.com/tsegayeh/ml_models_in_R/blob/main/Part_2.2_DecisionTree.R) model, the accuracy of which was 92% and covered 88% of the AUC. <br /><br />
Your review and comments will be highly appreciated.<br />
